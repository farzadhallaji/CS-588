{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad5ef56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda? True\n",
      "NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch, time\n",
    "print(\"cuda?\", torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"no cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87377d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading english: Package 'english' not found in\n",
      "[nltk_data]     index\n",
      "11/24/2025 15:35:58 - INFO - sentence_transformers.SentenceTransformer -   Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/24/2025 15:36:05 - INFO - sentence_transformers.SentenceTransformer -   1 prompt is loaded, with the key: query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con=1.000  Comp=0.500  Rel=0.667\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"CRScore\"))\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from src.metrics.claim_based.relevance_score import split_claims_and_impl\n",
    "\n",
    "claims_text = \"\"\"\n",
    "1. The code change is in the ProtocGapicPluginGeneratorTest class.\n",
    "2. The parameter is now \"language=java,transport=grpc\".\n",
    "3. Previously it was \"language=java\" only.\n",
    "Implications:\n",
    "1. Codegen now targets Java over gRPC.\n",
    "\"\"\"\n",
    "claims = split_claims_and_impl(claims_text)\n",
    "review = \"Adds gRPC transport to the Java codegen; check clients still build.\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sbert = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\", device=device)\n",
    "\n",
    "change_enc = sbert.encode(claims, convert_to_tensor=True, device=device, show_progress_bar=False)\n",
    "review_sentences = [s for s in review.split(\".\") if s.strip()] or [review]\n",
    "review_enc = sbert.encode(review_sentences, convert_to_tensor=True, device=device, show_progress_bar=False)\n",
    "\n",
    "sts = util.cos_sim(change_enc, review_enc)\n",
    "\n",
    "tau = 0.7314\n",
    "\n",
    "prec_mask = (sts.max(dim=0).values > tau).float()\n",
    "P = prec_mask.mean().item()\n",
    "rec_mask = (sts > tau).sum(dim=1) > 0\n",
    "R = rec_mask.float().mean().item()\n",
    "F = 0 if (P + R) == 0 else 2 * P * R / (P + R)\n",
    "\n",
    "print(f\"Con={P:.3f}  Comp={R:.3f}  Rel={F:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fecdff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx=6, lang=py, msg=alpha sort the imports\n",
      "smell path: /home/ri/Desktop/S2/DS/package/CRScore/experiments/python_code_smells/test6.json\n",
      "smell data: {'project_path': 'test6', 'stats': {'methods': 3, 'classes': 0, 'lambdas': 0, 'try': 1, 'listcomps': 0, 'codeblocks': 3}, 'smells': [['Code complexity smell detected with 1 of 3 code blocks having cyclomatic complexity of rank C or worse (rank C is moderate to slighly complex with cyclomatic complexity between 11 and 20).', -1]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "\n",
    "ROOT = Path(\"/home/ri/Desktop/S2/DS\")  # repo root\n",
    "split = \"test\"                         # msg-test.jsonl\n",
    "idx = 6                                # pick any index that exists\n",
    "\n",
    "data_path = ROOT / \"package\" / \"Comment_Generation\" / f\"msg-{split}.jsonl\"\n",
    "rec = json.loads(next(islice(data_path.open(), idx, None)))\n",
    "print(f\"idx={idx}, lang={rec['lang']}, msg={rec['msg']}\")\n",
    "\n",
    "# map language -> smell folder/extension\n",
    "smell_dir = {\"py\": \"python_code_smells\", \"java\": \"java_code_smells\", \"js\": \"javascript_code_smells\"}\n",
    "smell_ext = {\"py\": \"json\", \"java\": \"txt\", \"js\": \"txt\"}\n",
    "smell_path = ROOT / \"package\" / \"CRScore\" / \"experiments\" / smell_dir[rec[\"lang\"]] / f\"test{idx}.{smell_ext[rec['lang']]}\"\n",
    "\n",
    "if smell_path.suffix == \".json\":\n",
    "    smell = json.load(smell_path.open())\n",
    "else:\n",
    "    smell = smell_path.read_text()\n",
    "\n",
    "print(\"smell path:\", smell_path)\n",
    "print(\"smell data:\", smell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d41d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes you run this from /home/ri/Desktop/S2/DS/package\n",
    "import sys, json\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "\n",
    "# Make CRScore importable\n",
    "ROOT = Path.cwd() / \"CRScore\"\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "from src.datautils import read_jsonl\n",
    "from src.metrics.claim_based.relevance_score import (\n",
    "    RelevanceScorer,\n",
    "    split_claims_and_impl,\n",
    "    process_python_smells,\n",
    "    process_java_smells,\n",
    "    process_javascript_smells,\n",
    "    filter_by_changed_lines,\n",
    ")\n",
    "from scripts.create_code_smell_analysis_data import generate_newf\n",
    "\n",
    "# ------- choose the instance -------\n",
    "idx = 6          # 0-based row in msg-test.jsonl; change as needed\n",
    "split = \"test\"   # uses msg-test.jsonl + test_set_codepatch_ranges.json\n",
    "\n",
    "# ------- load the review + patch -------\n",
    "data = read_jsonl(ROOT / \"data\" / \"Comment_Generation\" / f\"msg-{split}.jsonl\")\n",
    "rec = data[idx]\n",
    "review = rec[\"msg\"]\n",
    "diff = rec[\"patch\"]\n",
    "lang = rec[\"lang\"]\n",
    "\n",
    "# ------- load code-change claims (LLM summary with implications) -------\n",
    "claims_file = ROOT / \"experiments\" / \"code_change_summ_finetune_impl\" / \"Magicoder-S-DS-6.7B.jsonl\"\n",
    "claims_text = json.loads(next(islice(claims_file.open(), idx, None)))[\"response\"]\n",
    "claims = split_claims_and_impl(claims_text)\n",
    "\n",
    "# ------- load smells (language-specific) and filter to changed lines -------\n",
    "patch_ranges = json.load(open(ROOT / \"data\" / \"Comment_Generation\" / \"test_set_codepatch_ranges.json\"))\n",
    "new_file, _ = generate_newf(rec[\"oldf\"], rec[\"patch\"])\n",
    "range_for_idx = patch_ranges[f\"test{idx}\"]\n",
    "\n",
    "smell_dir = {\"py\": \"python_code_smells\", \"java\": \"java_code_smells\", \"js\": \"javascript_code_smells\"}\n",
    "smell_ext = {\"py\": \"json\", \"java\": \"txt\", \"js\": \"txt\"}\n",
    "smell_path = ROOT / \"experiments\" / smell_dir[lang] / f\"test{idx}.{smell_ext[lang]}\"\n",
    "\n",
    "smells_raw = []\n",
    "if smell_path.exists():\n",
    "    if lang == \"py\":\n",
    "        smells_raw = process_python_smells(smell_path, smell_path.name)\n",
    "    elif lang == \"java\":\n",
    "        smells_raw = process_java_smells(smell_path, smell_path.name)\n",
    "    else:\n",
    "        smells_raw = process_javascript_smells(smell_path, smell_path.name)\n",
    "\n",
    "smells = filter_by_changed_lines(smells_raw, range_for_idx, new_file, diff)\n",
    "\n",
    "# ------- score review relevance (precision/recall/F1 over claims+smells) -------\n",
    "scorer = RelevanceScorer(model_path=\"mixedbread-ai/mxbai-embed-large-v1\", hi_sim_thresh=0.85)\n",
    "P, R, sts_matrix = scorer.compute_inst(claims + smells, review, debug=True)  # debug prints claim alignment\n",
    "F1 = 0 if (P + R) == 0 else (2 * P * R) / (P + R)\n",
    "\n",
    "print(f\"idx={idx}, lang={lang}\")\n",
    "print(f\"P={P:.3f}, R={R:.3f}, F1={F1:.3f}\")\n",
    "print(f\"{len(claims)} claims + {len(smells)} smells used\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run from /home/ri/Desktop/S2/DS/package\n",
    "import sys, json\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"CRScore\"\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "from src.metrics.claim_based.relevance_score import (\n",
    "    RelevanceScorer,\n",
    "    split_claims_and_impl,\n",
    "    filter_by_changed_lines,\n",
    "    process_python_smells,\n",
    "    process_java_smells,\n",
    "    process_javascript_smells,\n",
    ")\n",
    "from scripts.create_code_smell_analysis_data import generate_newf\n",
    "\n",
    "# ----------- YOUR INPUTS -----------\n",
    "review_text = \"\"\"<put the review you want to score here>\"\"\"\n",
    "\n",
    "claims_text = \"\"\"<put the code-change summary/implications text here; could be your own or model output>\"\"\"\n",
    "claims = split_claims_and_impl(claims_text)\n",
    "\n",
    "# If you have a unified diff + original file, fill these; else leave empty and smells will be skipped.\n",
    "patch = r\"\"\"<paste unified diff with @@ hunk header here>\"\"\"\n",
    "old_file_contents = \"\"\"<paste full original file contents here>\"\"\"\n",
    "\n",
    "# Optional: precomputed smell file path (py/json, java/txt, js/txt), else leave None and provide manual smells below.\n",
    "smell_file = None  # e.g., ROOT / \"experiments/python_code_smells/test6.json\"\n",
    "\n",
    "# Optional: manual smells if you want to supply them directly (list of (text, line_no))\n",
    "manual_smells = []  # e.g., [(\"line 42, Long Method smell ...\", 42)]\n",
    "# -----------------------------------\n",
    "\n",
    "# Build new file from diff if provided\n",
    "new_file = \"\"\n",
    "if patch.strip() and old_file_contents.strip():\n",
    "    new_file, _ = generate_newf(old_file_contents, patch)\n",
    "\n",
    "# Load smells if a file is provided\n",
    "smells_raw = []\n",
    "if smell_file:\n",
    "    if smell_file.suffix == \".json\":\n",
    "        smells_raw = process_python_smells(smell_file, smell_file.name)\n",
    "    elif smell_file.suffix == \".txt\":\n",
    "        # crude language guess from parent folder name\n",
    "        if \"java\" in smell_file.parts[-2]:\n",
    "            smells_raw = process_java_smells(smell_file, smell_file.name)\n",
    "        else:\n",
    "            smells_raw = process_javascript_smells(smell_file, smell_file.name)\n",
    "\n",
    "# Combine with any manual smells you typed in\n",
    "smells_raw.extend(manual_smells)\n",
    "\n",
    "# Filter smells to changed lines if we have diff + new file; otherwise keep as-is\n",
    "smells = smells_raw\n",
    "if new_file and patch:\n",
    "    smells = filter_by_changed_lines(smells_raw, [1, 10**9], new_file, patch)  # wide range; uses actual changed lines internally\n",
    "\n",
    "# Assemble claim/smell list and score\n",
    "claims_and_smells = claims + [s[0] if isinstance(s, (list, tuple)) else s for s in smells]\n",
    "\n",
    "scorer = RelevanceScorer(model_path=\"mixedbread-ai/mxbai-embed-large-v1\", hi_sim_thresh=0.85)\n",
    "P, R, sts = scorer.compute_inst(claims_and_smells, review_text, debug=True)\n",
    "F1 = 0 if (P + R) == 0 else 2 * P * R / (P + R)\n",
    "\n",
    "print(f\"P={P:.3f}, R={R:.3f}, F1={F1:.3f}\")\n",
    "print(f\"{len(claims)} claims + {len(smells)} smells used\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c51be28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/24/2025 17:09:30 - INFO - sentence_transformers.SentenceTransformer -   Use pytorch device_name: cuda:0\n",
      "11/24/2025 17:09:30 - INFO - sentence_transformers.SentenceTransformer -   Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1\n",
      "11/24/2025 17:09:40 - INFO - sentence_transformers.SentenceTransformer -   1 prompt is loaded, with the key: query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34;1mMost Relevant Claims/Smells for Review Claims:\u001b[0m\n",
      "P: 0.000, R: 0.000\n",
      "All change claims:\n",
      "['<put the code-change summary/implications text here; could be your own or model output>']\n",
      "CC: <put the code-change summary/implications text here; could be your own or model output> RC: <put the review you want to score here> sim: 0.542 rec_array: [0.5423967838287354]\n",
      "\n",
      "P=0.000, R=0.000, F1=0.000\n",
      "1 claims + 0 smells used\n"
     ]
    }
   ],
   "source": [
    "# Run from /home/ri/Desktop/S2/DS/package\n",
    "import sys, json\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd() / \"CRScore\"\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "from src.metrics.claim_based.relevance_score import (\n",
    "    RelevanceScorer,\n",
    "    split_claims_and_impl,\n",
    "    filter_by_changed_lines,\n",
    "    process_python_smells,\n",
    "    process_java_smells,\n",
    "    process_javascript_smells,\n",
    ")\n",
    "from scripts.create_code_smell_analysis_data import generate_newf\n",
    "\n",
    "# ----------- YOUR INPUTS -----------\n",
    "review_text = \"\"\"<put the review you want to score here>\"\"\"\n",
    "\n",
    "claims_text = \"\"\"<put the code-change summary/implications text here; could be your own or model output>\"\"\"\n",
    "claims = split_claims_and_impl(claims_text)\n",
    "\n",
    "# If you have a unified diff + original file, fill these; else leave empty and smells will be skipped.\n",
    "patch = r\"\"\"<paste unified diff with @@ hunk header here>\"\"\"\n",
    "old_file_contents = \"\"\"<paste full original file contents here>\"\"\"\n",
    "\n",
    "# Optional: precomputed smell file path (py/json, java/txt, js/txt), else leave None and provide manual smells below.\n",
    "smell_file = None  # e.g., ROOT / \"experiments/python_code_smells/test6.json\"\n",
    "\n",
    "# Optional: manual smells if you want to supply them directly (list of (text, line_no))\n",
    "manual_smells = []  # e.g., [(\"line 42, Long Method smell ...\", 42)]\n",
    "# -----------------------------------\n",
    "\n",
    "# Build new file from diff if provided\n",
    "new_file = \"\"\n",
    "if patch.strip() and old_file_contents.strip():\n",
    "    new_file, _ = generate_newf(old_file_contents, patch)\n",
    "\n",
    "# Load smells if a file is provided\n",
    "smells_raw = []\n",
    "if smell_file:\n",
    "    if smell_file.suffix == \".json\":\n",
    "        smells_raw = process_python_smells(smell_file, smell_file.name)\n",
    "    elif smell_file.suffix == \".txt\":\n",
    "        # crude language guess from parent folder name\n",
    "        if \"java\" in smell_file.parts[-2]:\n",
    "            smells_raw = process_java_smells(smell_file, smell_file.name)\n",
    "        else:\n",
    "            smells_raw = process_javascript_smells(smell_file, smell_file.name)\n",
    "\n",
    "# Combine with any manual smells you typed in\n",
    "smells_raw.extend(manual_smells)\n",
    "\n",
    "# Filter smells to changed lines if we have diff + new file; otherwise keep as-is\n",
    "smells = smells_raw\n",
    "if new_file and patch:\n",
    "    smells = filter_by_changed_lines(smells_raw, [1, 10**9], new_file, patch)  # wide range; uses actual changed lines internally\n",
    "\n",
    "# Assemble claim/smell list and score\n",
    "claims_and_smells = claims + [s[0] if isinstance(s, (list, tuple)) else s for s in smells]\n",
    "\n",
    "scorer = RelevanceScorer(model_path=\"mixedbread-ai/mxbai-embed-large-v1\", hi_sim_thresh=0.85)\n",
    "P, R, sts = scorer.compute_inst(claims_and_smells, review_text, debug=True)\n",
    "F1 = 0 if (P + R) == 0 else 2 * P * R / (P + R)\n",
    "\n",
    "print(f\"P={P:.3f}, R={R:.3f}, F1={F1:.3f}\")\n",
    "print(f\"{len(claims)} claims + {len(smells)} smells used\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8cdbeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986fb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "from statistics import mean\n",
    "from typing import Any, Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "\n",
    "def load_records(path: Path) -> List[Dict[str, Any]]:\n",
    "    raw = path.read_text().strip()\n",
    "    if not raw:\n",
    "        return []\n",
    "    if raw.startswith(\"[\"):\n",
    "        return json.loads(raw)\n",
    "    return [json.loads(line) for line in raw.splitlines() if line.strip()]\n",
    "\n",
    "\n",
    "def extract_review(entry: Dict[str, Any]) -> str:\n",
    "    for key in (\"review\", \"pred_review\", \"pred\", \"msg\", \"response\"):\n",
    "        val = entry.get(key)\n",
    "        if isinstance(val, str) and val.strip():\n",
    "            return val.strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def extract_diff(entry: Dict[str, Any]) -> str:\n",
    "    for key in (\"diff\", \"code_change\", \"patch\"):\n",
    "        val = entry.get(key)\n",
    "        if isinstance(val, str) and val.strip():\n",
    "            return val.strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def compute_score(entry: Dict[str, Any], mode: str) -> Optional[float]:\n",
    "\n",
    "    scores: Dict[str, Any] = entry.get(\"scores\") or entry.get(\"metric_scores\") or {}\n",
    "    has_scores_dict = isinstance(scores, dict)\n",
    "\n",
    "    if mode in (\"auto\", \"score\"):\n",
    "        val = entry.get(\"score\")\n",
    "        if isinstance(val, (int, float)):\n",
    "            return float(val)\n",
    "        if mode == \"score\":\n",
    "            return None\n",
    "\n",
    "    if not has_scores_dict:\n",
    "        return None\n",
    "\n",
    "    if \"relevance\" in scores:\n",
    "        return float(scores[\"relevance\"])\n",
    "    if \"F\" in scores:\n",
    "        return float(scores[\"F\"])\n",
    "\n",
    "    p = scores.get(\"conciseness\") if \"conciseness\" in scores else scores.get(\"P\")\n",
    "    r = scores.get(\"comprehensiveness\") if \"comprehensiveness\" in scores else scores.get(\"R\")\n",
    "    if isinstance(p, (int, float)) and isinstance(r, (int, float)):\n",
    "        denom = p + r\n",
    "        return 0.0 if denom == 0 else (2 * p * r) / denom\n",
    "\n",
    "    numeric_scores = [v for v in scores.values() if isinstance(v, (int, float))]\n",
    "    return mean(numeric_scores) if numeric_scores else None\n",
    "\n",
    "\n",
    "def select_extremes(\n",
    "    records: Iterable[Dict[str, Any]], k: int, mode: str\n",
    ") -> Tuple[List[Tuple[Dict[str, Any], float]], List[Tuple[Dict[str, Any], float]]]:\n",
    "    scored = []\n",
    "    for rec in records:\n",
    "        score = compute_score(rec, mode)\n",
    "        if score is not None:\n",
    "            scored.append((rec, score))\n",
    "    if not scored:\n",
    "        return [], []\n",
    "    ordered = sorted(scored, key=lambda item: item[1])\n",
    "    worst = ordered[:k]\n",
    "    best = list(reversed(ordered[-k:]))\n",
    "    return worst, best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eb4a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f94177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f9dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82add4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9f07a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idx', 'id', 'lang', 'review', 'patch'])\n",
      "idx: 0 id: 30879 lang: java\n",
      "review: can we also test for `transport=rest`?\n",
      "patch:\n",
      " @@ -53,7 +53,7 @@ public class ProtocGapicPluginGeneratorTest {\n",
      "                 model.getFiles().stream().map(ProtoFile::getProto).collect(Collectors.toList()))\n",
      "             // Only the file to generate a client for (don't generate dependencies)\n",
      "             .addFileToGenerate(\"multiple_services.proto\")\n",
      "-            .setParameter(\"language=java\")\n",
      "+            .setParameter(\"language=java,transport=grpc\")\n",
      "             .build();\n",
      " \n",
      "     CodeGeneratorResponse response = ProtocGeneratorMain.generate(codeGeneratorRequest);\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "\n",
    "def get_lowest_f_review(\n",
    "    scores_path=Path(\"CRScore/all_model_rel_scores_thresh_0.7314.json\"),\n",
    "    data_path=Path(\"Comment_Generation/msg-test.jsonl\"),\n",
    "    system=\"ground_truth\",\n",
    "):\n",
    "    scores = json.loads(scores_path.read_text())\n",
    "    f_vals = scores[system][\"F\"]\n",
    "    min_idx = min(range(len(f_vals)), key=f_vals.__getitem__)\n",
    "    rec = json.loads(next(islice(data_path.open(), min_idx, None)))\n",
    "    return {\n",
    "        \"idx\": min_idx,\n",
    "        \"id\": rec.get(\"id\"),\n",
    "        \"lang\": rec.get(\"lang\"),\n",
    "        \"review\": rec.get(\"msg\"),\n",
    "        \"patch\": rec.get(\"patch\"),\n",
    "    }\n",
    "\n",
    "bad = get_lowest_f_review()\n",
    "print(bad.keys())\n",
    "print(\"idx:\", bad[\"idx\"], \"id:\", bad[\"id\"], \"lang:\", bad[\"lang\"])\n",
    "print(\"review:\", bad[\"review\"])\n",
    "print(\"patch:\\n\", bad[\"patch\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190d813b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx=0 id=30879 lang=java\n",
      "P=0.000 R=0.000 F=0.000\n",
      "review: can we also test for `transport=rest`?\n",
      "patch:\n",
      " @@ -53,7 +53,7 @@ public class ProtocGapicPluginGeneratorTest {\n",
      "                 model.getFiles().stream().map(ProtoFile::getProto).collect(Collectors.toList()))\n",
      "             // Only the file to generate a client for (don't generate dependencies)\n",
      "             .addFileToGenerate(\"multiple_services.proto\")\n",
      "-            .setParameter(\"language=java\")\n",
      "+            .setParameter(\"language=java,transport=grpc\")\n",
      "             .build();\n",
      " \n",
      "     CodeGeneratorResponse response = ProtocGeneratorMain.generate(codeGeneratorRequest);\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "\n",
    "def get_lowest_f_review_with_score(\n",
    "    scores_path=Path(\"CRScore/all_model_rel_scores_thresh_0.7314.json\"),\n",
    "    data_path=Path(\"Comment_Generation/msg-test.jsonl\"),\n",
    "    system=\"ground_truth\",\n",
    "):\n",
    "    scores = json.loads(scores_path.read_text())\n",
    "    f_vals = scores[system][\"F\"]\n",
    "    p_vals = scores[system][\"P\"]\n",
    "    r_vals = scores[system][\"R\"]\n",
    "\n",
    "    min_idx = min(range(len(f_vals)), key=f_vals.__getitem__)\n",
    "    rec = json.loads(next(islice(data_path.open(), min_idx, None)))\n",
    "    return {\n",
    "        \"idx\": min_idx,\n",
    "        \"id\": rec.get(\"id\"),\n",
    "        \"lang\": rec.get(\"lang\"),\n",
    "        \"review\": rec.get(\"msg\"),\n",
    "        \"patch\": rec.get(\"patch\"),\n",
    "        \"P\": p_vals[min_idx],\n",
    "        \"R\": r_vals[min_idx],\n",
    "        \"F\": f_vals[min_idx],\n",
    "    }\n",
    "bad = get_lowest_f_review_with_score()\n",
    "print(f\"idx={bad['idx']} id={bad['id']} lang={bad['lang']}\"); print(f\"P={bad['P']:.3f} R={bad['R']:.3f} F={bad['F']:.3f}\"); print(\"review:\", bad[\"review\"]); print(\"patch:\\n\", bad[\"patch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55245ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num claims: 5\n",
      "- The code change is in the ProtocGapicPluginGeneratorTest class.\n",
      "- The change is in the setting of a parameter for the code generator request.\n",
      "- The parameter that is being set is \"language=java,transport=grpc\".\n",
      "- The previous parameter was \"language=java\".\n",
      "- The change in the code generator parameter from \"language=java\" to \"language=java,transport=grpc\" implies that the language is now set to java and the transport is set to grpc.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "ROOT = Path(\"/home/ri/Desktop/S2/DS/package\")\n",
    "import sys\n",
    "sys.path.append(str(ROOT / \"CRScore\"))\n",
    "from src.metrics.claim_based.relevance_score import split_claims_and_impl\n",
    "\n",
    "def get_java_claims(\n",
    "    split: str = \"test\",\n",
    "    claims_file: Path = ROOT / \"CRScore/experiments/code_change_summ_finetune_impl/Magicoder-S-DS-6.7B.jsonl\",\n",
    "    idx: Optional[int] = None,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Return the claims list for a Java example.\n",
    "    - split: which msg-{split}.jsonl to read (train/dev/test)\n",
    "    - claims_file: JSONL with code-change summaries+implications (aligned by index with msg file)\n",
    "    - idx: specific index; if None, pick the first Java example in msg-{split}.jsonl\n",
    "    \"\"\"\n",
    "    msg_path = ROOT / \"Comment_Generation\" / f\"msg-{split}.jsonl\"\n",
    "    if idx is None:\n",
    "        with msg_path.open() as f:\n",
    "            for i, line in enumerate(f):\n",
    "                rec = json.loads(line)\n",
    "                if rec.get(\"lang\") == \"java\":\n",
    "                    idx = i\n",
    "                    break\n",
    "        if idx is None:\n",
    "            raise ValueError(f\"No Java examples found in {msg_path}\")\n",
    "    claims_text = json.loads(next(islice(claims_file.open(), idx, None)))[\"response\"]\n",
    "    claims = split_claims_and_impl(claims_text)\n",
    "    return claims\n",
    "\n",
    "claims = get_java_claims(split=\"test\")\n",
    "print(\"Num claims:\", len(claims))\n",
    "for c in claims:\n",
    "    print(\"-\", c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7a1f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a refined review:\n",
      "\n",
      "The change to set `transport=grpc` for Java codegen is a good step forward. However, it would be beneficial to test the plugin with both `transport=rest` and `transport=grpc` scenarios to ensure the plugin behaves correctly in different transport modes.\n",
      "\n",
      "This change seems to be a necessary step towards enabling grpc transport for Java codegen, but it's essential to verify that the plugin works as expected in this new scenario.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from textwrap import dedent\n",
    "\n",
    "SYSTEM = dedent(\"\"\"\\\n",
    "You are a senior code reviewer. Improve the review so it is concise, specific, and aligned to the code diff and claims.\n",
    "- Address the main effects of the diff.\n",
    "- Call out correctness, safety, testing, and edge cases that matter.\n",
    "- Avoid generic or unrelated style nits.\n",
    "Output only the refined review text.\n",
    "\"\"\")\n",
    "\n",
    "def refine_with_ollama(review, claims, diff, model=\"llama3:8b-instruct-q4_0\"):\n",
    "    user = f\"Current review:\\n{review}\\n\\nClaims:\\n{claims}\\n\\nDiff:\\n{diff}\"\n",
    "    resp = requests.post(\n",
    "        \"http://127.0.0.1:11434/api/chat\",\n",
    "        json={\n",
    "            \"model\": \"llama3:8b-instruct-q4_0\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM},\n",
    "                {\"role\": \"user\", \"content\": user},\n",
    "            ],\n",
    "            \"options\": {\"temperature\": 0.2},\n",
    "            \"stream\": False, \n",
    "        },\n",
    "        timeout=60,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    refined = resp.json()[\"message\"][\"content\"].strip()\n",
    "\n",
    "    return refined\n",
    "\n",
    "review = \"can we also test for `transport=rest`?\"\n",
    "claims = \"\"\"- ProtocGapicPluginGeneratorTest now sets language=java,transport=grpc.\n",
    "- Previously it set language=java only.\n",
    "- This enables grpc transport for Java codegen.\"\"\"\n",
    "diff = \"\"\"@@ -53,7 +53,7 @@ public class ProtocGapicPluginGeneratorTest {\n",
    "-            .setParameter(\"language=java\")\n",
    "+            .setParameter(\"language=java,transport=grpc\")\n",
    " }\"\"\"\n",
    "\n",
    "refined = refine_with_ollama(review, claims, diff)\n",
    "print(refined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78bfa4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/25/2025 22:57:40 - INFO - sentence_transformers.SentenceTransformer -   Use pytorch device_name: cuda:0\n",
      "11/25/2025 22:57:40 - INFO - sentence_transformers.SentenceTransformer -   Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1\n",
      "11/25/2025 22:57:44 - INFO - sentence_transformers.SentenceTransformer -   1 prompt is loaded, with the key: query\n",
      "11/25/2025 22:57:44 - INFO - sentence_transformers.SentenceTransformer -   Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1\n",
      "11/25/2025 22:57:49 - INFO - sentence_transformers.SentenceTransformer -   1 prompt is loaded, with the key: query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P=0.500, R=0.667, F=0.571\n",
      "Refined review:\n",
      " Here's a refined review:\n",
      "\n",
      "The change to set `transport=grpc` for Java codegen is a good step forward. However, it would be beneficial to test the plugin with both `transport=rest` and `transport=grpc` scenarios to ensure the plugin behaves correctly in different transport modes.\n",
      "\n",
      "This change seems to be a necessary step towards enabling grpc transport for Java codegen, but it's essential to verify that the plugin works as expected in this new scenario.\n",
      "CRScore @ tau=0.7314 -> P=0.500 R=0.667 F=0.571\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Union, Iterable\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "ROOT = Path(\"/home/ri/Desktop/S2/DS/package/CRScore\")\n",
    "sys.path.append(str(ROOT))\n",
    "from src.metrics.claim_based.relevance_score import RelevanceScorer, split_claims_and_impl\n",
    "\n",
    "def crscore(\n",
    "    review_text: str,\n",
    "    claims_input: Union[str, Iterable[str]],\n",
    "    tau: float = 0.7314,\n",
    "    model_path: str = \"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "    use_gpu: bool = False,  # default CPU to avoid OOM\n",
    ") -> Tuple[float, float, float, str]:\n",
    "    device = \"cuda\" if (use_gpu and torch.cuda.is_available()) else \"cpu\"\n",
    "    scorer = RelevanceScorer(model_path=model_path, hi_sim_thresh=tau)\n",
    "    scorer.sbert = SentenceTransformer(model_path, device=device)\n",
    "    claims = split_claims_and_impl(claims_input) if isinstance(claims_input, str) else [str(c) for c in claims_input]\n",
    "    P, R, _ = scorer.compute_inst(claims, review_text, debug=False)\n",
    "    F = 0.0 if (P + R) == 0 else (2 * P * R) / (P + R)\n",
    "    return P, R, F, device\n",
    "\n",
    "P, R, F, device = crscore(refined, claims, tau=0.7314)\n",
    "print(f\"P={P:.3f}, R={R:.3f}, F={F:.3f}\")\n",
    "print(\"Refined review:\\n\", refined)\n",
    "print(f\"CRScore @ tau=0.7314 -> P={P:.3f} R={R:.3f} F={F:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe83d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Union, Iterable\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "ROOT = Path(\"/home/ri/Desktop/S2/DS/package/CRScore\")\n",
    "sys.path.append(str(ROOT))\n",
    "from src.metrics.claim_based.relevance_score import RelevanceScorer, split_claims_and_impl\n",
    "\n",
    "def crscore(\n",
    "    review_text: str,\n",
    "    claims_input: Union[str, Iterable[str]],\n",
    "    tau: float = 0.7314,\n",
    "    model_path: str = \"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "    use_gpu: bool = False,  # default CPU to avoid OOM\n",
    ") -> Tuple[float, float, float, str]:\n",
    "    device = \"cuda\" if (use_gpu and torch.cuda.is_available()) else \"cpu\"\n",
    "    scorer = RelevanceScorer(model_path=model_path, hi_sim_thresh=tau)\n",
    "    scorer.sbert = SentenceTransformer(model_path, device=device)\n",
    "    claims = split_claims_and_impl(claims_input) if isinstance(claims_input, str) else [str(c) for c in claims_input]\n",
    "    P, R, _ = scorer.compute_inst(claims, review_text, debug=False)\n",
    "    F = 0.0 if (P + R) == 0 else (2 * P * R) / (P + R)\n",
    "    return P, R, F, device\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "refined = \"\"\"The change correctly adds `transport=grpc` to the test parameters, enabling gRPC transport for Java codegen as claimed, without altering prior language=java behavior. For completeness, add a test case for `transport=rest` to verify it doesn't regress or conflict with gRPC logic—focus on edge cases like mixed transports or invalid combos. No safety issues noted, but ensure the generator handles absent transport params gracefully.\"\"\"\n",
    "\n",
    "P, R, F, device = crscore(refined, claims, tau=0.7314)\n",
    "print(f\"P={P:.3f}, R={R:.3f}, F={F:.3f}\")\n",
    "print(\"Refined review:\\n\", refined)\n",
    "print(f\"CRScore @ tau=0.7314 -> P={P:.3f} R={R:.3f} F={F:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1855d146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/25/2025 22:37:56 - INFO - sentence_transformers.SentenceTransformer -   Use pytorch device_name: cuda:0\n",
      "11/25/2025 22:37:56 - INFO - sentence_transformers.SentenceTransformer -   Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1\n",
      "11/25/2025 22:37:59 - INFO - sentence_transformers.SentenceTransformer -   1 prompt is loaded, with the key: query\n",
      "11/25/2025 22:37:59 - INFO - sentence_transformers.SentenceTransformer -   Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1\n",
      "11/25/2025 22:38:04 - INFO - sentence_transformers.SentenceTransformer -   1 prompt is loaded, with the key: query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P=0.667, R=0.600, F=0.632\n",
      "Refined review:\n",
      " The change correctly adds `transport=grpc` to the test parameters, enabling gRPC transport for Java codegen as claimed, without altering prior language=java behavior. For completeness, add a test case for `transport=rest` to verify it doesn't regress or conflict with gRPC logic—focus on edge cases like mixed transports or invalid combos. No safety issues noted, but ensure the generator handles absent transport params gracefully.\n",
      "CRScore @ tau=0.7314 -> P=0.667 R=0.600 F=0.632\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Union, Iterable\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "ROOT = Path(\"/home/ri/Desktop/S2/DS/package/CRScore\")\n",
    "sys.path.append(str(ROOT))\n",
    "from src.metrics.claim_based.relevance_score import RelevanceScorer, split_claims_and_impl\n",
    "\n",
    "def crscore(\n",
    "    review_text: str,\n",
    "    claims_input: Union[str, Iterable[str]],\n",
    "    tau: float = 0.7314,\n",
    "    model_path: str = \"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "    use_gpu: bool = False,  # default CPU to avoid OOM\n",
    ") -> Tuple[float, float, float, str]:\n",
    "    device = \"cuda\" if (use_gpu and torch.cuda.is_available()) else \"cpu\"\n",
    "    scorer = RelevanceScorer(model_path=model_path, hi_sim_thresh=tau)\n",
    "    scorer.sbert = SentenceTransformer(model_path, device=device)\n",
    "    claims = split_claims_and_impl(claims_input) if isinstance(claims_input, str) else [str(c) for c in claims_input]\n",
    "    P, R, _ = scorer.compute_inst(claims, review_text, debug=False)\n",
    "    F = 0.0 if (P + R) == 0 else (2 * P * R) / (P + R)\n",
    "    return P, R, F, device\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "refined = \"\"\"The change correctly adds `transport=grpc` to the test parameters, enabling gRPC transport for Java codegen as claimed, without altering prior language=java behavior. For completeness, add a test case for `transport=rest` to verify it doesn't regress or conflict with gRPC logic—focus on edge cases like mixed transports or invalid combos. No safety issues noted, but ensure the generator handles absent transport params gracefully.\"\"\"\n",
    "\n",
    "P, R, F, device = crscore(refined, claims, tau=0.7314)\n",
    "print(f\"P={P:.3f}, R={R:.3f}, F={F:.3f}\")\n",
    "print(\"Refined review:\\n\", refined)\n",
    "print(f\"CRScore @ tau=0.7314 -> P={P:.3f} R={R:.3f} F={F:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7706f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f62dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf5dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
